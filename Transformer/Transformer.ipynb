{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","import math\n","import json\n","import numpy as np\n","from tqdm import tqdm\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"id":"0GnXXS5W4V-h","executionInfo":{"status":"ok","timestamp":1662053838468,"user_tz":-540,"elapsed":38,"user":{"displayName":"­서장호","userId":"06110944139547681245"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2fe3e8dc-a6a2-42af-ed05-2e4f9f511bad"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset # 텐서데이터셋\n","from torch.utils.data import DataLoader # 데이터로더"],"metadata":{"id":"g9Rd5xr2OWLX","executionInfo":{"status":"ok","timestamp":1662053838470,"user_tz":-540,"elapsed":19,"user":{"displayName":"­서장호","userId":"06110944139547681245"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CR9-_BHYOWAo","executionInfo":{"status":"ok","timestamp":1662053841381,"user_tz":-540,"elapsed":2929,"user":{"displayName":"­서장호","userId":"06110944139547681245"}},"outputId":"5aae4984-5c1b-4779-a388-82d6e061683f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["PATH = \"drive/MyDrive/Implementation/Attention/\"\n","OUTPUT_PATH = \"drive/MyDrive/Implementation/Attention/\"\n","TRAIN_INPUT = 'train_input.npy'\n","TRAIN_OUTPUT = 'train_output.npy'\n","TRAIN_TARGET = 'train_target.npy'\n","DATA_CONFIGS = 'data_configs.json'"],"metadata":{"id":"S98AsljVOVPj","executionInfo":{"status":"ok","timestamp":1662053841382,"user_tz":-540,"elapsed":10,"user":{"displayName":"­서장호","userId":"06110944139547681245"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["idx_input = np.load(open(PATH+TRAIN_INPUT, 'rb'))\n","idx_output = np.load(open(PATH+TRAIN_OUTPUT, 'rb'))\n","idx_target = np.load(open(PATH+TRAIN_TARGET, 'rb'))\n","config = json.load(open(PATH+DATA_CONFIGS, 'r'))"],"metadata":{"id":"b1suDfSZPrdr","executionInfo":{"status":"ok","timestamp":1662053844394,"user_tz":-540,"elapsed":3020,"user":{"displayName":"­서장호","userId":"06110944139547681245"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["print(len(idx_input), len(idx_output), len(idx_target))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H5Nj_ixoPrWE","executionInfo":{"status":"ok","timestamp":1662053844396,"user_tz":-540,"elapsed":55,"user":{"displayName":"­서장호","userId":"06110944139547681245"}},"outputId":"c72d3b4f-6594-49f9-a5f7-2fc4d4fd56bf"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["11823 11823 11823\n"]}]},{"cell_type":"code","source":["idx_input.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g_A_UNJGqsnT","executionInfo":{"status":"ok","timestamp":1662053844397,"user_tz":-540,"elapsed":45,"user":{"displayName":"­서장호","userId":"06110944139547681245"}},"outputId":"b9c1749f-1f4e-4490-83b4-4d38da1e57de"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(11823, 20)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","execution_count":8,"metadata":{"id":"VNNbTs_YBUzO","executionInfo":{"status":"ok","timestamp":1662053844399,"user_tz":-540,"elapsed":41,"user":{"displayName":"­서장호","userId":"06110944139547681245"}}},"outputs":[],"source":["class ScaleDotProductAttention(nn.Module):\n","  def __init__(self):\n","    super(ScaleDotProductAttention, self).__init__()\n","    self.softmax = nn.Softmax(dim=3)\n","\n","  def forward(self, query, key, value, mask=None):\n","\n","    batch_size, head, length, d_tensor = key.size()\n","\n","    k_t = key.view(batch_size, head, d_tensor, length) # transpose\n","    score = (query.matmul(k_t)) / math.sqrt(d_tensor)\n","\n","    if mask is not None:\n","      score = score.masked_fill(mask == 0, -np.inf)\n","    \n","    score = self.softmax(score)\n","    value = score.matmul(value)\n","\n","    return value, score"]},{"cell_type":"code","source":["class MultiHeadAttention(nn.Module):\n","  def __init__(self, d_model, n_head):\n","    super(MultiHeadAttention, self).__init__()\n","    self.n_head = n_head\n","    self.attention = ScaleDotProductAttention()\n","\n","    # self-attention을 위한 vector 변환 : query, key, value vector 만들기\n","    self.w_q = nn.Linear(d_model, d_model)\n","    self.w_k = nn.Linear(d_model, d_model)\n","    self.w_v = nn.Linear(d_model, d_model)\n","\n","    self.w_concat = nn.Linear(d_model, d_model)\n","\n","  def forward(self, query, key, value, masked=None):\n","\n","    q, k, v = self.w_q(query), self.w_k(key), self.w_v(value)\n","\n","    q, k, v = self.split(q), self.split(k), self.split(v)\n","\n","    out, attnetion = self.attention(q, k, v, mask=masked)\n","\n","    out = self.concat(out)\n","    out = self.w_concat(out)\n","\n","    return out\n","\n","  def split(self, tensor):\n","\n","    batch_size, length, d_model = tensor.size()\n","    d_tensor = d_model // self.n_head\n","    tensor = tensor.view(batch_size, self.n_head, length, d_tensor)\n","\n","    return tensor\n","\n","  def concat(self, tensor):\n","\n","    batch_size, head, length, d_tensor = tensor.size()\n","    d_model = head*d_tensor\n","\n","    tensor = tensor.view(batch_size, length, d_model)\n","\n","    return tensor"],"metadata":{"id":"SPB4fbs1HjNx","executionInfo":{"status":"ok","timestamp":1662053844400,"user_tz":-540,"elapsed":40,"user":{"displayName":"­서장호","userId":"06110944139547681245"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["class LayerNorm(nn.Module):\n","  def __init__(self, d_model, eps=1e-45):\n","    super(LayerNorm, self).__init__()\n","    self.gamma = nn.Parameter(torch.ones(d_model))\n","    self.beta = nn.Parameter(torch.zeros(d_model))\n","    self.eps = eps\n","\n","  def forward(self, x):\n","    mean = x.mean(-1, keepdim=True)\n","    std = x.std(-1, keepdim=True)\n","\n","    out = (x - mean) / (std + self.eps)\n","    out = self.gamma * out + self.beta\n","\n","    return out"],"metadata":{"id":"j2ZafyVgYrgI","executionInfo":{"status":"ok","timestamp":1662053844403,"user_tz":-540,"elapsed":42,"user":{"displayName":"­서장호","userId":"06110944139547681245"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["class PostionwiseFeedForward(nn.Module):\n","  def __init__(self, d_model, hidden, drop_prob=0.1):\n","    super(PostionwiseFeedForward, self).__init__()\n","    self.linear1 = nn.Linear(d_model, hidden)\n","    self.linear2 = nn.Linear(hidden, d_model)\n","    self.relu = nn.ReLU()\n","    self.dropout = nn.Dropout(p=drop_prob)\n","\n","  def forward(self, x):\n","    x = self.linear1(x)\n","    x = self.relu(x)\n","    x = self.dropout(x)\n","    x = self.linear2(x)\n","\n","    return x"],"metadata":{"id":"PpQ6U0ypfTaG","executionInfo":{"status":"ok","timestamp":1662053844405,"user_tz":-540,"elapsed":43,"user":{"displayName":"­서장호","userId":"06110944139547681245"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["class EncoderLayer(nn.Module):\n","  def __init__(self, d_model, ffn_hidden, n_head, drop_prob):\n","    super(EncoderLayer, self).__init__()\n","    self.attention = MultiHeadAttention(d_model=d_model, n_head=n_head)\n","    self.norm1 = LayerNorm(d_model=d_model)\n","    self.dropout1 = nn.Dropout(p=drop_prob)\n","\n","    self.ffn = PostionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n","    self.norm2 = self.norm1 = LayerNorm(d_model=d_model)\n","    self.dropout2 = nn.Dropout(p=drop_prob)\n","\n","  def forward(self, x):\n","\n","    x_ = x\n","    x = self.attention(query=x, key=x, value=x, masked=None)\n","    \n","    x = self.norm1(x + x_)\n","    x = self.dropout1(x)\n","\n","    x_ = x\n","    x = self.ffn(x)\n","\n","    x = self.norm2(x + x_)\n","    x = self.dropout2(x)\n","\n","    return x"],"metadata":{"id":"njN38MLoN-gU","executionInfo":{"status":"ok","timestamp":1662053844407,"user_tz":-540,"elapsed":43,"user":{"displayName":"­서장호","userId":"06110944139547681245"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["class Encoder(nn.Module):\n","  def __init__(self, enc_voc_size, max_len, d_model, ffn_hidden, n_head, n_layers, drop_prob, device):\n","    super().__init__()\n","    self.emb = TransformerEmbedding(d_model=d_model,\n","                                    max_len=max_len,\n","                                    vocab_size=enc_voc_size,\n","                                    device=device)\n","\n","    self.layers = nn.ModuleList([EncoderLayer(d_model=d_model,\n","                                              ffn_hidden=ffn_hidden,\n","                                              n_head=n_head,\n","                                              drop_prob=drop_prob)\n","                                  for _ in range(n_layers)])\n","\n","  def forward(self, x):\n","    x = self.emb(x)\n","\n","    for layer in self.layers:\n","      x = layer(x)\n","\n","    return x"],"metadata":{"id":"BQ06Yki3hf01","executionInfo":{"status":"ok","timestamp":1662053844408,"user_tz":-540,"elapsed":43,"user":{"displayName":"­서장호","userId":"06110944139547681245"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["class DecoderLayer(nn.Module):\n","  def __init__(self, d_model, ffn_hidden, n_head, drop_prob):\n","    super(DecoderLayer, self).__init__()\n","    self.self_attention = MultiHeadAttention(d_model=d_model, n_head=n_head)\n","    self.norm1 = LayerNorm(d_model=d_model)\n","    self.dropout1 = nn.Dropout(p=drop_prob)\n","\n","    self.enc_dec_attention = MultiHeadAttention(d_model=d_model, n_head=n_head)\n","    self.norm2 = LayerNorm(d_model=d_model)\n","    self.dropout2 = nn.Dropout(p=drop_prob)\n","\n","    self.ffn = PostionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n","    self.norm3 = LayerNorm(d_model=d_model)\n","    self.dropout3 = nn.Dropout(p=drop_prob)\n","\n","  def forward(self, enc, dec, trg_mask):\n","\n","    x_ = dec\n","    x = self.self_attention(query=dec, key=dec, value=dec, masked=trg_mask)\n","\n","    x = self.norm1(x + x_)\n","    x = self.dropout1(x)\n","\n","    # if문 필요하나?\n","    if enc is not None:\n","      x_ = x\n","      x = self.enc_dec_attention(query=x, key=x, value=x, masked=None)\n","\n","      x = self.norm2(x + x_)\n","      x = self.dropout2(x)\n","\n","    x_ = x\n","    x = self.ffn(x)\n","\n","    x = self.norm3(x + x_)\n","    x = self.dropout3(x)\n","\n","    return x"],"metadata":{"id":"rZcS6gZWPhw6","executionInfo":{"status":"ok","timestamp":1662053844410,"user_tz":-540,"elapsed":44,"user":{"displayName":"­서장호","userId":"06110944139547681245"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["class Decoder(nn.Module):\n","  def __init__(self, dec_voc_size, max_len, d_model, ffn_hidden, n_head, n_layers, drop_prob, device):\n","    super().__init__()\n","    self.emb = TransformerEmbedding(d_model=d_model,\n","                                    max_len=max_len,\n","                                    vocab_size=dec_voc_size,\n","                                    device=device)\n","\n","    self.layers = nn.ModuleList([DecoderLayer(d_model=d_model,\n","                                              ffn_hidden=ffn_hidden,\n","                                              n_head=n_head,\n","                                              drop_prob=drop_prob)\n","                                  for _ in range(n_layers)])\n","\n","    self.linear = nn.Linear(d_model, dec_voc_size)\n","\n","  def forward(self, enc, dec_input, trg_mask):\n","    dec_input = self.emb(dec_input)\n","\n","    for layer in self.layers:\n","        dec_input = layer(enc, dec_input, trg_mask)\n","\n","    # pass to LM head\n","    output = self.linear(dec_input)\n","\n","    return output"],"metadata":{"id":"R6gmzj54hiCC","executionInfo":{"status":"ok","timestamp":1662053844411,"user_tz":-540,"elapsed":44,"user":{"displayName":"­서장호","userId":"06110944139547681245"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["class TransformerEmbedding(nn.Module):\n","  def __init__(self, vocab_size, d_model, max_len, device):\n","    super(TransformerEmbedding, self).__init__()\n","\n","    self.tok_emb = TokenEmbedding(vocab_size, d_model)\n","    self.pos_emb = PositionalEncoding(d_model, max_len, device)\n","\n","  def forward(self, x):\n","    tok_emb = self.tok_emb(x)\n","    pos_emb = self.pos_emb(x)\n","    \n","    return tok_emb + pos_emb"],"metadata":{"id":"1e23fiMjlTGm","executionInfo":{"status":"ok","timestamp":1662053844412,"user_tz":-540,"elapsed":44,"user":{"displayName":"­서장호","userId":"06110944139547681245"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["class PositionalEncoding(nn.Module):\n","  def __init__(self, d_model, max_len, device):\n","    super(PositionalEncoding, self).__init__()\n","\n","    # pos : word location\n","    # d_model : vector size\n","\n","    self.encoding = torch.zeros(max_len, d_model, device=device)\n","    # Gradient 계산 안해도 됨.\n","    self.encoding.requries_grad = False\n","\n","    pos = torch.arange(0, max_len, device=device)\n","    pos = pos.float().unsqueeze(dim=1)\n","    _2i = torch.arange(0, d_model, step=2, device=device).float()\n","\n","    self.encoding[:,0::2] = torch.sin(pos/(10000**(_2i / d_model)))\n","    self.encoding[:,1::2] = torch.cos(pos/(10000**(_2i / d_model)))\n","    \n","  def forward(self, x):\n","\n","    batch_size, seq_len = x.size()\n","\n","    return self.encoding[:seq_len, :]"],"metadata":{"id":"HlAPo9A1gEQF","executionInfo":{"status":"ok","timestamp":1662053844413,"user_tz":-540,"elapsed":43,"user":{"displayName":"­서장호","userId":"06110944139547681245"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["class TokenEmbedding(nn.Embedding):\n","  def __init__(self, voca_size, d_model):\n","    super(TokenEmbedding, self).__init__(voca_size, d_model)"],"metadata":{"id":"I6GCx_t3lyUo","executionInfo":{"status":"ok","timestamp":1662053844414,"user_tz":-540,"elapsed":43,"user":{"displayName":"­서장호","userId":"06110944139547681245"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["class Transformer(nn.Module):\n","\n","  def __init__(self, enc, dec):\n","      super().__init__()\n","      \n","      self.encoder = enc\n","      self.decoder = dec\n","\n","  def forward(self, input, output, target):\n","\n","      out_mask = self.make_pad_mask(input, output)\n","      \n","      enc_src = self.encoder(input)\n","      output = self.decoder(enc_src, output, out_mask)\n","\n","      return output\n","\n","  def make_pad_mask(self, input, output):\n","\n","    query_seq_len, key_seq_len = input.size(1), output.size(1)\n","\n","    tril = np.tril(np.ones((query_seq_len, key_seq_len)), k=0)\n","    mask = torch.tensor(tril, requires_grad=False, device=device)\n","\n","    return mask"],"metadata":{"id":"80Orn6wtnVii","executionInfo":{"status":"ok","timestamp":1662053844416,"user_tz":-540,"elapsed":43,"user":{"displayName":"­서장호","userId":"06110944139547681245"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["def Model(model, input_tensor, output_tensor, target_tensor, model_optimizer, criterion):\n","\n","  model_optimizer.zero_grad()\n","\n","  loss = 0\n","  epoch_loss = 0\n","\n","  output = model(input_tensor, output_tensor, target_tensor)\n","\n","  output_ = output.view(-1,output.shape[-1])\n","  target_ = F.one_hot(target_tensor, num_classes=VOCA_SIZE)\n","  target_ = target_.view(-1, target_.shape[-1]).type(torch.FloatTensor).to(device)\n","\n","  loss = criterion(output_, target_)\n","\n","  loss.backward()\n","  model_optimizer.step()\n","  epoch_loss = loss.item()\n","\n","  return epoch_loss"],"metadata":{"id":"QZMpaA8gCfdi","executionInfo":{"status":"ok","timestamp":1662053844417,"user_tz":-540,"elapsed":43,"user":{"displayName":"­서장호","userId":"06110944139547681245"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def TrainModel(model, train_data, epoch=1000):\n","  \n","  optimizer = optim.Adam(model.parameters(), lr=0.001) # SGD\n","  criterion = nn.CrossEntropyLoss()\n","\n","  model.train()\n","\n","  for iter in range(epoch):\n","    loss = 0\n","    for input, output, target in tqdm(train):\n","      loss += Model(model, input, output, target, optimizer, criterion)\n","    \n","    if iter%1 == 0:\n","      print('iteration :%d\\ntrain_loss : %.4f' % (iter, loss/len(train)))\n","\n","  return model"],"metadata":{"id":"xm-ZL9TxCgDI","executionInfo":{"status":"ok","timestamp":1662053844419,"user_tz":-540,"elapsed":44,"user":{"displayName":"­서장호","userId":"06110944139547681245"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["train_input = torch.LongTensor(idx_input[1823:]).to(device)\n","train_output = torch.LongTensor(idx_output[1823:]).to(device)\n","train_target = torch.LongTensor(idx_target[1823:]).to(device)\n","test_input = torch.LongTensor(idx_input[:1823]).to(device)\n","test_output = torch.LongTensor(idx_output[:1823]).to(device)\n","test_target = torch.LongTensor(idx_target[:1823]).to(device)"],"metadata":{"id":"Sw3H06racqcg","executionInfo":{"status":"ok","timestamp":1662053846587,"user_tz":-540,"elapsed":2211,"user":{"displayName":"­서장호","userId":"06110944139547681245"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["dataset = TensorDataset(train_input, train_output, train_target)\n","train = DataLoader(dataset, batch_size=128, shuffle=True)"],"metadata":{"id":"t43pDaEjiZfK","executionInfo":{"status":"ok","timestamp":1662053846589,"user_tz":-540,"elapsed":24,"user":{"displayName":"­서장호","userId":"06110944139547681245"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["MAX_SEQUENCE = 20\n","EPOCH = 30\n","HEAD = 4\n","UNITS = 128\n","DROPOUT = 0.2\n","NUM_LAYERS = 2\n","BATCH_SIZE = 64\n","EMBEDDING_DIM = 128\n","VOCA_SIZE = config['voca_size']"],"metadata":{"id":"YcqOICbClsHN","executionInfo":{"status":"ok","timestamp":1662053846590,"user_tz":-540,"elapsed":21,"user":{"displayName":"­서장호","userId":"06110944139547681245"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["Enc = Encoder(enc_voc_size=VOCA_SIZE, max_len=MAX_SEQUENCE, d_model=EMBEDDING_DIM, ffn_hidden=UNITS, n_head=HEAD, n_layers=NUM_LAYERS, drop_prob=DROPOUT, device=device)\n","Dec = Decoder(dec_voc_size=VOCA_SIZE, max_len=MAX_SEQUENCE, d_model=EMBEDDING_DIM, ffn_hidden=UNITS, n_head=HEAD, n_layers=NUM_LAYERS, drop_prob=DROPOUT, device=device)"],"metadata":{"id":"vYTb7nedihor","executionInfo":{"status":"ok","timestamp":1662053846591,"user_tz":-540,"elapsed":20,"user":{"displayName":"­서장호","userId":"06110944139547681245"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["tf = Transformer(Enc, Dec).to(device)"],"metadata":{"id":"oPxceuNIzA-P","executionInfo":{"status":"ok","timestamp":1662053846592,"user_tz":-540,"elapsed":19,"user":{"displayName":"­서장호","userId":"06110944139547681245"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["model = TrainModel(tf, train, epoch=EPOCH)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oSFZuk1d-DFS","outputId":"cdbe7438-1090-4075-f230-d9c28fe35f90","executionInfo":{"status":"ok","timestamp":1662054543878,"user_tz":-540,"elapsed":697303,"user":{"displayName":"­서장호","userId":"06110944139547681245"}}},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 79/79 [00:27<00:00,  2.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["iteration :0\n","train_loss : 2.8376\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 79/79 [00:23<00:00,  3.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["iteration :1\n","train_loss : 1.6092\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 79/79 [00:23<00:00,  3.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["iteration :2\n","train_loss : 1.5415\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 79/79 [00:23<00:00,  3.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["iteration :3\n","train_loss : 1.4849\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 79/79 [00:22<00:00,  3.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["iteration :4\n","train_loss : 1.4344\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 79/79 [00:23<00:00,  3.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["iteration :5\n","train_loss : 1.3828\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 79/79 [00:23<00:00,  3.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["iteration :6\n","train_loss : 1.3368\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 79/79 [00:23<00:00,  3.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["iteration :7\n","train_loss : 1.2839\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 79/79 [00:23<00:00,  3.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["iteration :8\n","train_loss : 1.2352\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 79/79 [00:23<00:00,  3.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["iteration :9\n","train_loss : 1.1813\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 79/79 [00:23<00:00,  3.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["iteration :10\n","train_loss : 1.1188\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 79/79 [00:22<00:00,  3.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["iteration :11\n","train_loss : 1.0478\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 79/79 [00:22<00:00,  3.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["iteration :12\n","train_loss : 0.9765\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 79/79 [00:22<00:00,  3.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["iteration :13\n","train_loss : 0.8995\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 79/79 [00:22<00:00,  3.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["iteration :14\n","train_loss : 0.8308\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 79/79 [00:22<00:00,  3.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["iteration :15\n","train_loss : 0.7550\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 79/79 [00:23<00:00,  3.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["iteration :16\n","train_loss : 0.6834\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 79/79 [00:22<00:00,  3.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["iteration :17\n","train_loss : 0.6195\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 79/79 [00:23<00:00,  3.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["iteration :18\n","train_loss : 0.5602\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 79/79 [00:22<00:00,  3.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["iteration :19\n","train_loss : 0.5064\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 79/79 [00:22<00:00,  3.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["iteration :20\n","train_loss : 0.4529\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 79/79 [00:22<00:00,  3.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["iteration :21\n","train_loss : 0.4050\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 79/79 [00:23<00:00,  3.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["iteration :22\n","train_loss : 0.3603\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 79/79 [00:22<00:00,  3.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["iteration :23\n","train_loss : 0.3212\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 79/79 [00:23<00:00,  3.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["iteration :24\n","train_loss : 0.2826\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 79/79 [00:22<00:00,  3.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["iteration :25\n","train_loss : 0.2547\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 79/79 [00:23<00:00,  3.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["iteration :26\n","train_loss : 0.2258\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 79/79 [00:22<00:00,  3.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["iteration :27\n","train_loss : 0.2004\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 79/79 [00:23<00:00,  3.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["iteration :28\n","train_loss : 0.1807\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 79/79 [00:23<00:00,  3.41it/s]"]},{"output_type":"stream","name":"stdout","text":["iteration :29\n","train_loss : 0.1613\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}